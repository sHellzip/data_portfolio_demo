import streamlit as st
import pandas as pd
import plotly.express as px
from openai import OpenAI
import numpy as np
import plotly.graph_objects as go

# -----------------------------------------------------------------------------
# 0. ç®€å†æ•°æ® (System Prompt Context)
# -----------------------------------------------------------------------------
RESUME_CONTENT = """
My name is Shuyue Hou. I am applying for a Data Analyst / Data Scientist role.
Here is my resume content:

[Contact]
Email: shou003@e.ntu.edu.sg | LinkedIn: Shuyue Hou

[Education]
1. M.Sc. in Signal Processing and Machine Learning, Nanyang Technological University (Aug 2024-Jun 2025). Grade: 3.3/5.0.
2. B.Sc. in Statistics, Beijing Institute of Technology (Sep 2019-Jun 2023). Grade: 90/100.
Awards: Academic Excellence Award (2020, 2023), Red Forest Scholarship.

[Experience]
1. Machine Learning Engineer @ Pingan Bank (Aug 2025-Present)
- Developed Rate/Mix decomposition engine (Python/Pandas) for $10B+ deposit campaigns.
- Designed GenAI-powered dashboard (LLM/Agent) reducing report time by 98%.
- Engineered ETL pipeline (SQL & Python) ensuring 100% data integrity.

2. Co-founder @ OfferLah, Singapore (Feb 2025-Present)
- Automated scheduling system reducing admin overhead by 40%.
- Funnel Analysis identified 15% drop-off; UI/UX redesign improved conversion by 20%.

3. Data Analyst Intern @ Xiaohongshu (RED) (Dec 2023-May 2024)
- Analyzed 300,000+ user behaviors via SQL.
- Bidding Strategy optimized budget, increased ROAS by 25%.
- Built Power BI dashboards reducing reporting time by 50%.

[Projects]
1. Financial Transaction Risk Dashboard: Tableau, LOD Expressions, Pareto Analysis.
2. Ensemble Text Classification System: Python, Scikit-Learn, NLP, TF-IDF, AHP (85% precision/recall).

[Skills]
Python, SQL (Advanced), Tableau, Power BI, GenAI/LLM, ETL, Anomaly Detection.
"""


# -----------------------------------------------------------------------------
# 1. é¡µé¢é…ç½® 
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="Shuyue's Data Portfolio",
    layout="wide",
    page_icon="ğŸ“Š",
    initial_sidebar_state="expanded"
)

# -----------------------------------------------------------------------------
# 2. ä¾§è¾¹æ ï¼šä¸ªäººä¿¡æ¯ (Sidebar)
# -----------------------------------------------------------------------------
with st.sidebar:

    st.image("materials/selfie.png", width=150)

    st.title("Shuyue Hou")
    st.markdown("**Machine Learning Engineer | Data Analyst**")
    st.markdown("ğŸ“ **M.Sc. @ NTU (Signal Processing and Machine Learning)**")
    st.markdown("ğŸ“ **B.Sc. @ BIT (Statistics)**")

    st.divider()

    # è”ç³»æ–¹å¼
    st.write("ğŸ“§ shou003@e.ntu.edu.sg")
    st.write("ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/olivia-h-44721b304/)")
    st.write("ğŸ”— [Tableau Portfolio](https://public.tableau.com/app/profile/shuyue.hou)")

    st.divider()

    # ç®€å†ä¸‹è½½
    try:
        with open("materials/resume.pdf", "rb") as pdf_file:
            st.download_button(
                label="ğŸ“„ Download PDF Resume",
                data=pdf_file,
                file_name="Shuyue_Hou_Resume.pdf",
                mime="application/pdf"
            )
    except FileNotFoundError:
        st.warning("âš ï¸ Resume file not found in materials/")

# -----------------------------------------------------------------------------
# 3. ä¸»é¡µæ ‡é¢˜ä¸ Intro
# -----------------------------------------------------------------------------
st.title("ğŸ‘‹ Hi, I'm Shuyue.")
st.markdown("""
### Applying for the **Data Analyst / Data Scientist** Role
> ğŸš€ **Why Me?**  
> I turn complex data into **actionable business decisions** and production-ready solutions.  
>  
> I specialize in **end-to-end analytics** â€” from problem framing and metric design to insight generation and productization  
> (**Data Analysis â†’ Business Insight â†’ AI Application â†’ Product Delivery**).  
>  
> At *Ping An Bank*, I built anomaly diagnosis engines and GenAI-powered reporting tools that reduced analysis time from days to hours.  
> At *Xiaohongshu*, I optimized bidding strategies through user behavior analysis, driving measurable ROAS growth.  
>  
> My strength lies in combining **SQL, Python, and statistical thinking** with **AI integration and product mindset** to solve real business problems at scale.
""")

# -----------------------------------------------------------------------------
# 4. æ ¸å¿ƒå†…å®¹åˆ†æ  (Tabs)
# -----------------------------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["ğŸš€ Experience & Skills", "âœ¨ Chat with My Resume", "ğŸ“ˆ Interactive Analysis"])

# =============================================================================
# TAB 1: ç®€å†æ·±åº¦è§£æ (Experience & Skills)
# =============================================================================
with tab1:
    # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šæŠ€èƒ½çŸ©é˜µ (é’ˆå¯¹ JD ä¼˜åŒ–) ---
    st.header("ğŸ› ï¸ Technical Arsenal")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("#### ğŸ’» Programming & Data")
        st.write("âœ… **Python (Pandas, Scikit-Learn)**")
        st.write("âœ… **SQL (Advanced/MySQL)**")
        st.write("âœ… **Java & Data Cleaning & Git**")

    with col2:
        st.markdown("#### ğŸ“Š Visualization & BI")
        st.write("âœ… **Tableau & Power BI**")
        st.write("âœ… **GenAI Automated Reporting**")
        st.write("âœ… **Excel (VBA, Pivot Tables)**")

    with col3:
        st.markdown("#### ğŸ§  Analytics & AI")
        st.write("âœ… **Statistics Background**")  # JD Keyword
        st.write("âœ… **A/B Testing & Anomaly Detection**")
        st.write("âœ… **LLM / Agent Development**")

    st.divider()

    # --- ç¬¬äºŒéƒ¨åˆ†ï¼šèŒä¸šç»å† (Professional Experience) ---
    st.header("ğŸ¢ Professional Experience")

    # ç»å† 1: Pingan Bank
    with st.container():
        st.subheader("Machine Learning Engineer | Pingan Bank Co.,Ltd.")
        st.caption("Aug 2025 - Present (Full Time) | Shenzhen")

        st.markdown("""
        *   **Business Driver & Root Cause Analysis:** Developed a Rate/Mix decomposition engine to **quantify drivers** behind CTR/CVR fluctuations for **$10B+ campaigns**. Reduced anomaly diagnosis time from days to hours.
        *   **GenAI-powered Dashboard:** Designed an **LLM-Agent dashboard** that auto-generates diagnostic reports, slashing reporting time by **98%**. 
        *   **Data Pipeline (ETL):** Engineered a robust **Source-ETL-Model pipeline** (SQL & Python) to resolve T0/T1 data alignment, ensuring **100% data integrity** for attribution models.
        """)
        st.success("ğŸ’¡ **Impact:** Solved the 'Business-Technology Challenge' by automating manual diagnostics with GenAI.")

    # ç»å† 2: Xiaohongshu
    with st.container():
        st.subheader("Data Analyst Intern | Xiaohongshu (RED)")
        st.caption("Dec 2023 - May 2024 | Beijing")

        st.markdown("""
        *   **Strategic Bidding (SQL):** Analyzed **300,000+ user search behaviors using SQL**. Identified long-tail keywords to optimize budget allocation.
        *   **Business Impact:** Drove a **25% increase in ROAS** and 18% growth in sales volume by capturing niche user intent.
        *   **Dashboarding:** Developed automated **Power BI dashboards** to visualize real-time metrics (CTR, CVR, CPA), reducing reporting time by 50%.
        """)
        st.success("ğŸ’¡ **Impact:** Demonstrated data-driven growth capability by translating user behavior insights into bidding strategies that significantly improved ROAS and revenue.")

    st.divider()

    # --- åˆ›ä¸šç»å† (Entrepreneurship) ---
    st.header("ğŸš€ Entrepreneurship Experience")

    with st.container():
        st.subheader("Co-founder | OfferLah (Startup)")
        st.caption("Feb 2025 - Present | Singapore")

        st.markdown("""
        *   **Operational System Design & Automation:** Spearheaded the migration from **manual spreadsheets to an automated scheduling ecosystem**. Established a centralized data tracking system that **reduced admin overhead by 40%**.
        *   **Funnel Analysis & User Growth:** Defined full-funnel conversion metrics. Identified a **15% drop-off** at the service inquiry stage using data visualization, prompting a UI/UX redesign that improved the **Lead-to-Customer conversion rate by 20%**.
        """)
        st.success(
            "ğŸŒŸ **Highlight:** Demonstrated full-cycle ability from defining metrics -> identifying problems -> implementing solutions.")

    st.divider()

    # --- ç¬¬å››éƒ¨åˆ†ï¼šé¡¹ç›® (Projects) ---
    st.header("ğŸ“‚ Key Projects")

    col_p1, col_p2 = st.columns(2)

    with col_p1:
        st.markdown("**ğŸ’° Financial Transaction Risk Dashboard**")
        st.markdown("*Tableau, LOD Expressions, Pareto Analysis*")
        st.markdown(
            "Identified **anomalies and high-risk transactions** using dynamic thresholding. Solved resource allocation challenges.")
        st.markdown("[ğŸ”— View Dashboard](https://public.tableau.com/app/profile/shuyue.hou)")

    with col_p2:
        st.markdown("**ğŸ“ Ensemble Text Classification System**")
        st.markdown("*Python, Scikit-Learn, NLP, TF-IDF*")
        st.markdown(
            "Engineered a text processing pipeline and implemented **AHP (Analytic Hierarchy Process)** to improve precision/recall to over 85%.")
        st.markdown("[ğŸ”— View GitHub](https://github.com/sHellzip/question_pair)")

# =============================================================================
# TAB 2: AI Chat (Doubao / Volcengine Integration)
# =============================================================================
with tab2:
    st.header("âœ¨ Chat with My Resume")
    st.caption("Powered by Doubao (Volcengine) LLM")

    # -------------------------------------------------------------------------
    # 1. åˆå§‹åŒ– API Client
    # -------------------------------------------------------------------------
    # ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæš‚æ—¶ç›´æ¥åœ¨è¿™é‡Œå¡« Keyã€‚
    # æ­£å¼éƒ¨ç½²æ—¶å»ºè®®ä½¿ç”¨ st.secrets["ARK_API_KEY"]
    try:
        my_api_key = st.secrets["ARK_API_KEY"]
    except FileNotFoundError:
        st.error("âš ï¸ API Key æœªæ‰¾åˆ°ã€‚è¯·åœ¨æœ¬åœ°é…ç½® .streamlit/secrets.toml æˆ–åœ¨äº‘ç«¯é…ç½® Secretsã€‚")
        st.stop()

    if not my_api_key:
        st.warning("âš ï¸ Please provide a valid API Key in the code to activate the chatbot.")
    else:
        client = OpenAI(
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=my_api_key,
        )

        # ---------------------------------------------------------------------
        # 2. åˆå§‹åŒ–èŠå¤©å†å²
        # ---------------------------------------------------------------------
        if "messages" not in st.session_state:
            st.session_state.messages = []
            # å¼€åœºç™½
            welcome_msg = "Hello! I am Shuyue's AI Assistant. Ask me anything about her experience, Project details, or Education!"
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

        # ---------------------------------------------------------------------
        # 3. æ˜¾ç¤ºå†å²æ¶ˆæ¯
        # ---------------------------------------------------------------------
        for msg in st.session_state.messages:
            st.chat_message(msg["role"]).write(msg["content"])

        # ---------------------------------------------------------------------
        # 4. å¤„ç†ç”¨æˆ·è¾“å…¥
        # ---------------------------------------------------------------------
        if prompt := st.chat_input("Ask about my experience (e.g., 'Tell me about the RED project')"):

            # 4.1 æ˜¾ç¤ºç”¨æˆ·æé—®
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.chat_message("user").write(prompt)

            # 4.2 æ„é€ å‘é€ç»™ AI çš„æ¶ˆæ¯åˆ—è¡¨ (System Prompt + History)
            # æˆ‘ä»¬æŠŠ RESUME_CONTENT ä½œä¸º System Prompt è—åœ¨æœ€å‰é¢ï¼Œä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
            api_messages = [
                {"role": "system",
                 "content": f"You are a helpful assistant representing Shuyue Hou. Answer questions based strictly on this resume context:\n\n{RESUME_CONTENT}\n\nIf the answer is not in the resume, say you don't know but offer to contact Shuyue directly."}
            ]

            # è¿½åŠ å†å²å¯¹è¯ (ä¸ºäº†è®© AI æœ‰è®°å¿†)
            for m in st.session_state.messages:
                api_messages.append({"role": m["role"], "content": m["content"]})

            # 4.3 è°ƒç”¨è±†åŒ… API
            try:
                with st.chat_message("assistant"):
                    stream = client.chat.completions.create(
                        model="doubao-seed-1-8-251228",  # ä½ çš„ Endpoint ID
                        messages=api_messages,
                        stream=True
                    )
                    # æµå¼è¾“å‡º
                    response = st.write_stream(stream)

                # 4.4 ä¿å­˜ AI å›å¤åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": response})

            except Exception as e:
                st.error(f"Error connecting to AI: {e}")


# =============================================================================
# TAB 3: å¤šç»´æ¯”ç‡å½’å› å¼•æ“ (Rate/Mix + Beam Search)
# =============================================================================
with tab3:
    st.header("ğŸ“‰ Metric Attribution Engine (Rate/Mix + Beam Search)")
    st.markdown("""
    This module simulates the **Root Cause Analysis System** I developed using Python.
    Unlike traditional dashboards, it uses a **Beam Search Algorithm** to automatically traverse high-dimensional data 
    and decompose Ratio Metrics (e.g., CTR, CVR) into **Rate Effect** (Efficiency) vs. **Mix Effect** (Structure).
    """)


    # -------------------------------------------------------------------------
    # 1. å®šä¹‰æ ¸å¿ƒç®—æ³•é€»è¾‘
    # -------------------------------------------------------------------------
    def calculate_ratio_contribution_v2(node_ratio_t0, node_ratio_t1, w_t0, w_t1):
        """
        Reflecting the exact logic from my project code:
        Rate Effect = (Rate_t1 - Rate_t0) * W_t1
        Mix Effect  = (W_t1 - W_t0) * Rate_t0
        """
        rate_effect = (node_ratio_t1 - node_ratio_t0) * w_t1
        mix_effect = (w_t1 - w_t0) * node_ratio_t0
        return rate_effect, mix_effect


    st.divider()

    # -------------------------------------------------------------------------
    # 2. æ¨¡æ‹Ÿä¸šåŠ¡åœºæ™¯æ•°æ® (Simulation Data)
    # -------------------------------------------------------------------------
    # åœºæ™¯ï¼šCTR ä¸‹é™ã€‚
    # åŸå› ï¼šè™½ç„¶ Search (é«˜CTR) å’Œ Feed (ä½CTR) çš„å„è‡ª CTR éƒ½æ²¡æ€ä¹ˆè·Œï¼Œ
    # ä½† Feed çš„æµé‡å æ¯”ä» 50% æ¶¨åˆ°äº† 80%ï¼Œå¯¼è‡´å¤§ç›˜ CTR è¢«æ‹‰ä½ (å…¸å‹çš„ Mix Effect)ã€‚

    # T0 (Base Periodï¼šåŸºæœŸï¼Œä¹Ÿå°±æ˜¯å‚ç…§çš„å¯¹æ¯”ç»„)
    clicks_t0 = 5000
    imp_t0 = 100000
    ctr_t0 = clicks_t0 / imp_t0  # 5.0%

    # T1 (Current Periodï¼šå½“æœŸï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯ç°åœ¨è¿™ä¸ªæ—¶æœŸ)
    # æ¨¡æ‹Ÿï¼šCTR æ‰åˆ°äº† 3.8%
    clicks_t1 = 4560
    imp_t1 = 120000  # æ›å…‰æ¶¨äº†
    ctr_t1 = clicks_t1 / imp_t1  # 3.8%

    delta_ctr = ctr_t1 - ctr_t0  # -1.2%

    # æ¨¡æ‹Ÿç¬¬ä¸€å±‚å½’å› ç»“æœ (Global Level Decomposition)
    # æ±‡æ€»äº†æ‰€æœ‰å­èŠ‚ç‚¹çš„ Rate Effect å’Œ Mix Effect


    # æ•…äº‹ï¼šMix Effect (ç»“æ„) è´¡çŒ®äº†ç»å¤§éƒ¨åˆ†è·Œå¹… (-1.0%)ï¼ŒRate Effect (æ•ˆç‡) åªè·Œäº†ä¸€ç‚¹ç‚¹ (-0.2%)
    total_rate_effect = -0.002
    total_mix_effect = -0.010

    # -------------------------------------------------------------------------
    # 3. æ ¸å¿ƒæŒ‡æ ‡çœ‹æ¿ (KPIs)
    # -------------------------------------------------------------------------
    col_kpi1, col_kpi2, col_kpi3 = st.columns(3)
    col_kpi1.metric("Global CTR (Period T0)", f"{ctr_t0 * 100:.2f}%")
    col_kpi2.metric("Global CTR (Period T1)", f"{ctr_t1 * 100:.2f}%", delta=f"{delta_ctr * 100:.2f}%",
                    delta_color="inverse")
    col_kpi3.metric("Attribution Status", "âš ï¸ Mix-Driven Drop")

    # -------------------------------------------------------------------------
    # 4. ç¬¬ä¸€å±‚ï¼šRate/Mix ç€‘å¸ƒå›¾ (Waterfall)
    # -------------------------------------------------------------------------
    st.subheader("1ï¸âƒ£ Global Attribution: Rate vs. Mix")
    st.caption(
        "Did the CTR drop because ads performed worse (Rate), or because traffic shifted to low-CTR channels (Mix)?")

    fig_waterfall = go.Figure(go.Waterfall(
        name="CTR Decomposition", orientation="v",
        measure=["relative", "relative", "relative", "total"],
        x=["CTR T0", "Rate Effect (Efficiency)", "Mix Effect (Structure)", "CTR T1"],
        textposition="outside",
        text=[f"{ctr_t0 * 100:.2f}%", f"{total_rate_effect * 100:.2f}%", f"{total_mix_effect * 100:.2f}%",
              f"{ctr_t1 * 100:.2f}%"],
        y=[ctr_t0, total_rate_effect, total_mix_effect, ctr_t1],
        connector={"line": {"color": "rgb(63, 63, 63)"}},
        decreasing={"marker": {"color": "#FF4B4B"}},
        increasing={"marker": {"color": "#2ECC71"}},
        totals={"marker": {"color": "#1F77B4"}}
    ))
    fig_waterfall.update_layout(title="Drivers of CTR Drop", height=400, yaxis_tickformat=".2%")
    st.plotly_chart(fig_waterfall, use_container_width=True)

    st.info("""
    **ğŸ§  Insight:** 
    The waterfall reveals a **Structural Issue (Mix Effect)**. 
    The negative impact comes primarily from **Mix Effect (-1.0%)**, meaning high-quality traffic volume decreased or low-quality traffic increased. 
    Efficiency (Rate Effect) remained relatively stable.
    """)

    # -------------------------------------------------------------------------
    # 5. ç¬¬äºŒå±‚ï¼šBeam Search è‡ªåŠ¨ä¸‹é’»ç»“æœ (Automated Drill-down)
    # -------------------------------------------------------------------------
    st.subheader("2ï¸âƒ£ Automated Root Cause Discovery (Beam Search)")
    st.markdown("""
    The system executed a **Beam Search** algorithm (Top-K pruning) across dimensions: `Channel`, `App_Version`, `User_Tag`.
    Here are the **Top Negative Contributors** identified automatically:
    """)

    if st.button("ğŸš€ Run Beam Search Algorithm"):
        import time

        # æ¨¡æ‹Ÿè®¡ç®—
        with st.spinner('Running multidimensional decomposition algorithm...'):
            time.sleep(1.5)

        # æ¨¡æ‹Ÿ Beam Search è¿”å›çš„ flat_negative ç»“æœåˆ—è¡¨
        beam_results = [
            {
                "Path (Dimension Combination)": "Channel=Feed_Flow",
                "CTR T0": "2.5%",
                "CTR T1": "2.4%",
                "Weight T0": "50%",
                "Weight T1": "80% (â¬†)",  # æµé‡å æ¯”æš´æ¶¨ï¼Œæ‹‰ä½äº†å¤§ç›˜
                "Contribution": "-0.85%"
            },
            {
                "Path (Dimension Combination)": "Region=Tier3_Cities",
                "CTR T0": "3.0%",
                "CTR T1": "2.9%",
                "Weight T0": "20%",
                "Weight T1": "35% (â¬†)",
                "Contribution": "-0.15%"
            },
            {
                "Path (Dimension Combination)": "App_Version=v10.5 -> Channel=Search",
                "CTR T0": "12.0%",
                "CTR T1": "10.5% (â¬‡)",  # çœŸçš„è·Œäº†
                "Weight T0": "10%",
                "Weight T1": "10%",
                "Contribution": "-0.12%"
            }
        ]

        # å°†ç»“æœè½¬æ¢ä¸º DataFrame å±•ç¤º
        df_results = pd.DataFrame(beam_results)

        # é«˜äº®å±•ç¤º
        st.dataframe(
            df_results.style.map(lambda x: 'color: red' if 'Negative' in str(x) or '-' in str(x) else 'color: black'),
            use_container_width=True
        )

        st.success("""
        **ğŸ¯ Root Cause Found:** 
        The primary driver is the significant **traffic shift towards 'Feed_Flow'** (Mix Effect). 
        While 'Feed_Flow' CTR is stable, its volume share increased from 50% to 80%, diluting the overall performance.
        **Action:** Re-evaluate bid adjustment for Feed Flow traffic.
        """)