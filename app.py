import streamlit as st
import pandas as pd
import plotly.express as px
from openai import OpenAI
import numpy as np

# -----------------------------------------------------------------------------
# 0. ç®€åŽ†æ•°æ® (System Prompt Context)
# -----------------------------------------------------------------------------
RESUME_CONTENT = """
My name is Shuyue Hou. I am applying for a Data Analyst / Data Scientist role.
Here is my resume content:

[Contact]
Email: shou003@e.ntu.edu.sg | LinkedIn: Shuyue Hou

[Education]
1. M.Sc. in Signal Processing and Machine Learning, Nanyang Technological University (Aug 2024-Jun 2025). Grade: 3.3/5.0.
2. B.Sc. in Statistics, Beijing Institute of Technology (Sep 2019-Jun 2023). Grade: 90/100.
Awards: Academic Excellence Award (2020, 2023), Red Forest Scholarship.

[Experience]
1. Machine Learning Engineer @ Pingan Bank (Aug 2025-Present)
- Developed Rate/Mix decomposition engine (Python/Pandas) for $10B+ deposit campaigns.
- Designed GenAI-powered dashboard (LLM/Agent) reducing report time by 98%.
- Engineered ETL pipeline (SQL & Python) ensuring 100% data integrity.

2. Co-founder @ OfferLah, Singapore (Feb 2025-Present)
- Automated scheduling system reducing admin overhead by 40%.
- Funnel Analysis identified 15% drop-off; UI/UX redesign improved conversion by 20%.

3. Data Analyst Intern @ Xiaohongshu (RED) (Dec 2023-May 2024)
- Analyzed 300,000+ user behaviors via SQL.
- Bidding Strategy optimized budget, increased ROAS by 25%.
- Built Power BI dashboards reducing reporting time by 50%.

[Projects]
1. Financial Transaction Risk Dashboard: Tableau, LOD Expressions, Pareto Analysis.
2. Ensemble Text Classification System: Python, Scikit-Learn, NLP, TF-IDF, AHP (85% precision/recall).

[Skills]
Python, SQL (Advanced), Tableau, Power BI, GenAI/LLM, ETL, Anomaly Detection.
"""


# -----------------------------------------------------------------------------
# 1. é¡µé¢é…ç½® 
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="Shuyue's Data Portfolio",
    layout="wide",
    page_icon="ðŸ“Š",
    initial_sidebar_state="expanded"
)

# -----------------------------------------------------------------------------
# 2. ä¾§è¾¹æ ï¼šä¸ªäººä¿¡æ¯ (Sidebar)
# -----------------------------------------------------------------------------
with st.sidebar:
    # ç¡®ä¿ materials/selfie.png å­˜åœ¨ï¼Œå¦åˆ™ä¼šæ˜¾ç¤ºç ´å›¾å›¾æ ‡
    # å¦‚æžœè¿˜æ²¡ç…§ç‰‡ï¼Œæš‚æ—¶æ³¨é‡ŠæŽ‰ä¸‹é¢è¿™è¡Œ
    st.image("materials/selfie.png", width=150)

    st.title("Shuyue Hou")
    st.markdown("**Machine Learning Engineer | Data Analyst**")
    st.markdown("ðŸŽ“ **M.Sc. @ NTU (Signal Processing and Machine Learning)**")
    st.markdown("ðŸŽ“ **B.Sc. @ BIT (Statistics)**")

    st.divider()

    # è”ç³»æ–¹å¼
    st.write("ðŸ“§ shou003@e.ntu.edu.sg")
    st.write("ðŸ”— [LinkedIn Profile](https://www.linkedin.com/in/olivia-h-44721b304/)")  # æ›¿æ¢ä¸ºä½ çš„çœŸå®žé“¾æŽ¥
    st.write("ðŸ”— [Tableau Portfolio](https://public.tableau.com/app/profile/shuyue.hou)")

    st.divider()

    # ç®€åŽ†ä¸‹è½½
    try:
        with open("materials/resume.pdf", "rb") as pdf_file:
            st.download_button(
                label="ðŸ“„ Download PDF Resume",
                data=pdf_file,
                file_name="Shuyue_Hou_Resume.pdf",
                mime="application/pdf"
            )
    except FileNotFoundError:
        st.warning("âš ï¸ Resume file not found in materials/")

# -----------------------------------------------------------------------------
# 3. ä¸»é¡µæ ‡é¢˜ä¸Ž Intro
# -----------------------------------------------------------------------------
st.title("ðŸ‘‹ Hi, I'm Shuyue.")
st.markdown("""
### Applying for the **Data Analyst / Data Scientist** Role
> ðŸš€ **Why Me?**  
> I bridge the gap between **Complex Data Engineering** and **Business Strategy**.  
> From building **Anomaly diagnosis** & **GenAI dashboards** at *Pingan Bank* to optimizing **Bidding Strategies** at *Xiaohongshu*, 
> I leverage **SQL, Python, and Anomaly Detection** to solve business-technology challenges.
""")

# -----------------------------------------------------------------------------
# 4. æ ¸å¿ƒå†…å®¹åˆ†æ  (Tabs)
# -----------------------------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["ðŸš€ Experience & Skills", "âœ¨ Chat with My Resume", "ðŸ“ˆ Interactive Analysis"])

# =============================================================================
# TAB 1: ç®€åŽ†æ·±åº¦è§£æž (Experience & Skills)
# =============================================================================
with tab1:
    # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šæŠ€èƒ½çŸ©é˜µ (é’ˆå¯¹ JD ä¼˜åŒ–) ---
    st.header("ðŸ› ï¸ Technical Arsenal")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("#### ðŸ’» Programming & Data")
        st.write("âœ… **Python (Pandas, Scikit-Learn)**")
        st.write("âœ… **SQL (Advanced/MySQL)**")
        st.write("âœ… **Java & Data Cleaning & Git**")

    with col2:
        st.markdown("#### ðŸ“Š Visualization & BI")
        st.write("âœ… **Tableau & Power BI**")
        st.write("âœ… **GenAI Automated Reporting**")
        st.write("âœ… **Excel (VBA, Pivot Tables)**")

    with col3:
        st.markdown("#### ðŸ§  Analytics & AI")
        st.write("âœ… **Statistics Background**")  # JD Keyword
        st.write("âœ… **A/B Testing & Anomaly Detection**")
        st.write("âœ… **LLM / Agent Development**")

    st.divider()

    # --- ç¬¬äºŒéƒ¨åˆ†ï¼šèŒä¸šç»åŽ† (Professional Experience) ---
    st.header("ðŸ¢ Professional Experience")

    # ç»åŽ† 1: Pingan Bank
    with st.container():
        st.subheader("Machine Learning Engineer | Pingan Bank Co.,Ltd.")
        st.caption("Aug 2025 - Present (Full Time) | Shenzhen")

        st.markdown("""
        *   **Business Driver & Root Cause Analysis:** Developed a Rate/Mix decomposition engine to **quantify drivers** behind CTR/CVR fluctuations for **$10B+ campaigns**. Reduced anomaly diagnosis time from days to hours.
        *   **GenAI-powered Dashboard:** Designed an **LLM-Agent dashboard** that auto-generates diagnostic reports, slashing reporting time by **98%**. *(Directly matches JD: Support dashboards & reports)*
        *   **Data Pipeline (ETL):** Engineered a robust **Source-ETL-Model pipeline** (SQL & Python) to resolve T0/T1 data alignment, ensuring **100% data integrity** for attribution models.
        """)
        st.success("ðŸ’¡ **Impact:** Solved the 'Business-Technology Challenge' by automating manual diagnostics with GenAI.")

    # ç»åŽ† 2: Xiaohongshu
    with st.container():
        st.subheader("Data Analyst Intern | Xiaohongshu (RED)")
        st.caption("Dec 2023 - May 2024 | Beijing")

        st.markdown("""
        *   **Strategic Bidding (SQL):** Analyzed **300,000+ user search behaviors using SQL**. Identified long-tail keywords to optimize budget allocation.
        *   **Business Impact:** Drove a **25% increase in ROAS** and 18% growth in sales volume by capturing niche user intent.
        *   **Dashboarding:** Developed automated **Power BI dashboards** to visualize real-time metrics (CTR, CVR, CPA), reducing reporting time by 50%.
        """)

    st.divider()

    # --- åˆ›ä¸šç»åŽ† (Entrepreneurship) ---
    st.header("ðŸš€ Entrepreneurship Experience")

    with st.container():
        st.subheader("Co-founder | OfferLah (Startup)")
        st.caption("Feb 2025 - Present | Singapore")

        st.markdown("""
        *   **Operational System Design & Automation:** Spearheaded the migration from **manual spreadsheets to an automated scheduling ecosystem**. Established a centralized data tracking system that **reduced admin overhead by 40%**.
        *   **Funnel Analysis & User Growth:** Defined full-funnel conversion metrics. Identified a **15% drop-off** at the service inquiry stage using data visualization, prompting a UI/UX redesign that improved the **Lead-to-Customer conversion rate by 20%**.
        """)
        st.success(
            "ðŸŒŸ **Highlight:** Demonstrated full-cycle ability from defining metrics -> identifying problems -> implementing solutions.")

    st.divider()

    # --- ç¬¬å››éƒ¨åˆ†ï¼šé¡¹ç›® (Projects) ---
    st.header("ðŸ“‚ Key Projects")

    col_p1, col_p2 = st.columns(2)

    with col_p1:
        st.markdown("**ðŸ’° Financial Transaction Risk Dashboard**")
        st.markdown("*Tableau, LOD Expressions, Pareto Analysis*")
        st.markdown(
            "Identified **anomalies and high-risk transactions** using dynamic thresholding. Solved resource allocation challenges.")
        st.markdown("[ðŸ”— View Dashboard](https://public.tableau.com/app/profile/shuyue.hou)")

    with col_p2:
        st.markdown("**ðŸ“ Ensemble Text Classification System**")
        st.markdown("*Python, Scikit-Learn, NLP, TF-IDF*")
        st.markdown(
            "Engineered a text processing pipeline and implemented **AHP (Analytic Hierarchy Process)** to improve precision/recall to over 85%.")
        st.markdown("[ðŸ”— View GitHub](https://github.com/sHellzip/question_pair)")

# =============================================================================
# TAB 2: AI Chat (Doubao / Volcengine Integration)
# =============================================================================
with tab2:
    st.header("âœ¨ Chat with My Resume")
    st.caption("Powered by Doubao (Volcengine) LLM")

    # -------------------------------------------------------------------------
    # 1. åˆå§‹åŒ– API Client
    # -------------------------------------------------------------------------
    # ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæš‚æ—¶ç›´æŽ¥åœ¨è¿™é‡Œå¡« Keyã€‚
    # æ­£å¼éƒ¨ç½²æ—¶å»ºè®®ä½¿ç”¨ st.secrets["ARK_API_KEY"]
    try:
        my_api_key = st.secrets["ARK_API_KEY"]
    except FileNotFoundError:
        st.error("âš ï¸ API Key æœªæ‰¾åˆ°ã€‚è¯·åœ¨æœ¬åœ°é…ç½® .streamlit/secrets.toml æˆ–åœ¨äº‘ç«¯é…ç½® Secretsã€‚")
        st.stop()

    if not my_api_key:
        st.warning("âš ï¸ Please provide a valid API Key in the code to activate the chatbot.")
    else:
        client = OpenAI(
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=my_api_key,
        )

        # ---------------------------------------------------------------------
        # 2. åˆå§‹åŒ–èŠå¤©åŽ†å²
        # ---------------------------------------------------------------------
        if "messages" not in st.session_state:
            st.session_state.messages = []
            # å¼€åœºç™½
            welcome_msg = "Hello! I am Shuyue's AI Assistant. Ask me anything about her experience, Project details, or Education!"
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

        # ---------------------------------------------------------------------
        # 3. æ˜¾ç¤ºåŽ†å²æ¶ˆæ¯
        # ---------------------------------------------------------------------
        for msg in st.session_state.messages:
            st.chat_message(msg["role"]).write(msg["content"])

        # ---------------------------------------------------------------------
        # 4. å¤„ç†ç”¨æˆ·è¾“å…¥
        # ---------------------------------------------------------------------
        if prompt := st.chat_input("Ask about my experience (e.g., 'Tell me about the RED project')"):

            # 4.1 æ˜¾ç¤ºç”¨æˆ·æé—®
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.chat_message("user").write(prompt)

            # 4.2 æž„é€ å‘é€ç»™ AI çš„æ¶ˆæ¯åˆ—è¡¨ (System Prompt + History)
            # æˆ‘ä»¬æŠŠ RESUME_CONTENT ä½œä¸º System Prompt è—åœ¨æœ€å‰é¢ï¼Œä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
            api_messages = [
                {"role": "system",
                 "content": f"You are a helpful assistant representing Shuyue Hou. Answer questions based strictly on this resume context:\n\n{RESUME_CONTENT}\n\nIf the answer is not in the resume, say you don't know but offer to contact Shuyue directly."}
            ]

            # è¿½åŠ åŽ†å²å¯¹è¯ (ä¸ºäº†è®© AI æœ‰è®°å¿†)
            for m in st.session_state.messages:
                api_messages.append({"role": m["role"], "content": m["content"]})

            # 4.3 è°ƒç”¨è±†åŒ… API
            try:
                with st.chat_message("assistant"):
                    stream = client.chat.completions.create(
                        model="doubao-seed-1-8-251228",  # ä½ çš„ Endpoint ID
                        messages=api_messages,
                        stream=True
                    )
                    # æµå¼è¾“å‡º (æ‰“å­—æœºæ•ˆæžœ)
                    response = st.write_stream(stream)

                # 4.4 ä¿å­˜ AI å›žå¤åˆ°åŽ†å²
                st.session_state.messages.append({"role": "assistant", "content": response})

            except Exception as e:
                st.error(f"Error connecting to AI: {e}")


# =============================================================================
# TAB 3: Interactive Analysis (The "Show Me" Part)
# =============================================================================
with tab3:
    st.header("ðŸ“Š Interactive Data Analysis Demo")
    st.write(
        "This interactive dashboard simulates the **Anomaly Detection & ROAS Optimization** logic I implemented at *Pingan Bank* and *Xiaohongshu*.")

    # --- 1. æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ (Data Simulation) --- #

    dates = pd.date_range(start="2024-01-01", periods=90)

    # æ¨¡æ‹ŸåŸºç¡€è¶‹åŠ¿
    base_traffic = np.linspace(1000, 5000, 90)  # é€æ­¥å¢žé•¿
    noise = np.random.normal(0, 200, 90)  # éšæœºæ³¢åŠ¨
    traffic = base_traffic + noise

    # æ¨¡æ‹Ÿè½¬åŒ–çŽ‡ (CVR)
    cvr = np.random.uniform(0.02, 0.05, 90)

    # æ’å…¥â€œå¼‚å¸¸ç‚¹â€ (Anomalies) - æ¨¡æ‹ŸæŸå¤©æœåŠ¡å™¨æ•…éšœæˆ–æŠ•æ”¾äº‹æ•…
    traffic[20] = 500  # æš´è·Œ
    traffic[65] = 8000  # æš´æ¶¨
    cvr[20] = 0.005  # è½¬åŒ–çŽ‡å¼‚å¸¸ä½Ž

    # ç»„è£… DataFrame
    df_demo = pd.DataFrame({
        "Date": dates,
        "Traffic (Clicks)": traffic,
        "CVR (Conversion Rate)": cvr,
        "Cost": traffic * np.random.uniform(0.5, 0.8, 90),
    })
    df_demo["Revenue"] = df_demo["Traffic (Clicks)"] * df_demo["CVR (Conversion Rate)"] * 100
    df_demo["ROAS"] = df_demo["Revenue"] / df_demo["Cost"]

    # --- 2. äº¤äº’æŽ§åˆ¶åŒº (Interactive Widgets) ---
    col_ctrl1, col_ctrl2 = st.columns([1, 3])

    with col_ctrl1:
        st.markdown("#### âš™ï¸ Settings")
        metric_choice = st.selectbox("Select Metric to Analyze:", ["Traffic (Clicks)", "ROAS", "Revenue"])
        show_anomaly = st.checkbox("ðŸ” Detect Anomalies (Auto)", value=True)

    with col_ctrl2:
        # --- 3. ç»˜åˆ¶å›¾è¡¨ (Visualization) ---

        # è®¡ç®—åŠ¨æ€é˜ˆå€¼ (å…¬å¼ï¼šlimit = å‡å€¼ Â± 2å€æ ‡å‡†å·®)
        mean_val = df_demo[metric_choice].mean()
        std_val = df_demo[metric_choice].std()
        upper_limit = mean_val + 2 * std_val
        lower_limit = mean_val - 2 * std_val

        # æ ‡è®°å¼‚å¸¸ç‚¹
        df_demo["Type"] = "Normal"
        if show_anomaly:
            df_demo.loc[df_demo[metric_choice] > upper_limit, "Type"] = "Anomaly (High)"
            df_demo.loc[df_demo[metric_choice] < lower_limit, "Type"] = "Anomaly (Low)"

        # ç»˜å›¾
        fig = px.scatter(
            df_demo,
            x="Date",
            y=metric_choice,
            color="Type",  # é¢œè‰²åŒºåˆ†å¼‚å¸¸ç‚¹
            color_discrete_map={"Normal": "#1f77b4", "Anomaly (High)": "#2ca02c", "Anomaly (Low)": "#d62728"},
            title=f"Time Series Analysis: {metric_choice} with Thresholding",
            height=400
        )

        # åŠ ä¸Šè¶‹åŠ¿çº¿
        fig.add_scatter(x=df_demo["Date"], y=[mean_val] * 90, mode='lines', name='Average',
                        line=dict(dash='dash', color='gray'))

        st.plotly_chart(fig, use_container_width=True)

    st.divider()

    # --- 4. ä¸šåŠ¡æ´žå¯Ÿ (Business Insight) ---
    st.info(f"""
    **ðŸ’¡ Automated Insight:**
    *   The system automatically flagged **{len(df_demo[df_demo['Type'] != 'Normal'])} data points** as statistical anomalies.
    *   In a real-world scenario (like my experience at *Pingan Bank*), this triggers an automated alert to the Ops team, reducing diagnosis time from **days to hours**.
    """)
